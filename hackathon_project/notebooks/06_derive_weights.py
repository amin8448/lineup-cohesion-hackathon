import sys
sys.path.insert(0, '../src')
import pandas as pd
import statsmodels.api as sm
from pathlib import Path

# Load your season summary data (generated by 03_full_analysis.py)
DATA_DIR = Path('../data')
df = pd.read_csv(DATA_DIR / 'team_season_summary.csv')

print(f"Loaded {len(df)} teams for regression analysis.")

# 1. Prepare the Feature Matrix (X)
# We use the raw components. 
# CRITICAL: We invert 'balance' to create 'hub_dependence' because your hypothesis
# states that high inequality (hub dependence) is GOOD.
df['hub_dependence'] = 1 - df['cohesion_balance']

features = ['cohesion_connectivity', 'cohesion_chemistry', 'hub_dependence', 'cohesion_progression']
X = df[features]
y = df['points']

# 2. Standardize the data (Z-scores)
# This is crucial so the coefficients are comparable. 
# If we don't do this, a variable with small range (0.0-0.1) might get a huge coefficient 
# just to scale up, not because it's important.
X_scaled = (X - X.mean()) / X.std()

# 3. Add a constant (intercept) 
# This represents the "baseline points" a team gets with average cohesion.
X_scaled = sm.add_constant(X_scaled)

# 4. Fit the Ordinary Least Squares (OLS) model
model = sm.OLS(y, X_scaled).fit()

# 5. Output the results for the paper
print(model.summary())

print("\n" + "="*30)
print("YOUR NEW SCIENTIFIC WEIGHTS")
print("="*30)
print("These are the coefficients to use in your paper:")
for name, coef in model.params.items():
    if name != 'const':
        print(f"{name}: {coef:.4f}")

print("\n INTERPRETATION GUIDE:")
print("- If a coefficient is POSITIVE, it positively correlates with winning.")
print("- If 'hub_dependence' is positive, your 'Paradox' hypothesis is statistically proven.")
print("- The 'P>|t|' column tells you if the component is statistically significant (aim for < 0.05).")